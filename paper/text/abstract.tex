\par The human brain receives signals flooding in from various senses, each using a different part of the brain to analyze and interpret them. We attempt to use fMRI data to find correlations between brain activity and events occurring in an audio movie stimuli and make predictions about events occurring in the movie. A previous study on semantic modeling has shown that given the natural movie stimuli, it is possible to predict semantic categories only using the BOLD responses \cite{stansbury2013neuron}. In this study we aim to loosely follow this structure, giving rise to two modeling goals for this project. The first is to model brain activity given the audio description of the movie. We aim to predict BOLD response time course for every voxel using words/categories a subject is listening to. The second goal is to predict what scene occurs in the audio movie based on the BOLD response/brain image at that time. To accomplish these goals requires preprocessing BOLD responses as well as the movie description via NLP (Natural Language Processing) of the script using WordNet. Modeling methods include K-Nearest Neighbors for non-parametric analysis, ridge ($L2$) and lasso ($L1$) regression for voxel encoding, and neural network for BOLD response decoding. Each model accuracy was measured using different relevant statistics.

%\par The human brain receives and interprets signals flooding in from various senses, each using different parts of the brain  We attempt to use fMRI data to find correlations between brain activity and events occurring in an audio movie stimuli and make predictions about events occurring in the movie. A previous study on semantic modeling has shown that given the natural movie stimuli, it is possible to predict semantic categories only using the BOLD responses \cite{stansbury2013neuron}. The data we used in this project includes a detailed transcript of an audio movie ('Forest Gump'), a description of the movie scenes divided into windows by time, and the BOLD response of 20 subjects listening to the audio movie \cite{Hanke}. There are two modeling goals for this project. The first is to model brain activity given the audio description of the movie. We aim to predict BOLD response time course for every voxel using words/categories a subject is listening to. The second goal is to predict what scene occurs in the audio movie based on the BOLD response/brain image at that time. To accomplish these goals requires preprocessing BOLD responses as well as the movie description. This involves NLP (Natural Language Processing) of the script using WordNet, as well as modeling methods such as K-Nearest Neighbors, ridge regression, and neural networks. With an overall 34$\%$ of the scene labels correctly matched, our results show that most scenes are not well identifiable by the brain images. 
